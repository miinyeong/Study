{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"7RugCy2KwlFv"},"source":["# 3. 데이터 불러오기\n","\n","딥러닝을 포함한 머신러닝의 근원은 데이터다. 따라서 데이터의 수집, 가공, 사용 방법에 따라 모델 성능이 크게 달라질 수 있으며 데이터의 형태는 매우 다양하기 때문에 데이터를 잘 불러오는 것은 가장 중요한 단계 중 하나다."]},{"cell_type":"code","metadata":{"id":"uhxYHQotwlF-","executionInfo":{"status":"ok","timestamp":1673867179204,"user_tz":-60,"elapsed":4436,"user":{"displayName":"딥러닝호형","userId":"11263585794403583722"}}},"source":["import torch # 파이토치 기본 라이브러리 \n","import torchvision # 이미지 관련 된 파이토치 라이브러리\n","import torchvision.transforms as tr # 이미지 전처리 기능들을 제공하는 라이브러리\n","from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n","import numpy as np # 넘파이 기본 라이브러리"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yfZJ6yVFwlF_"},"source":["## 3.1 파이토치 제공 데이터 사용"]},{"cell_type":"code","metadata":{"id":"ikDNDryOwlF_","executionInfo":{"status":"ok","timestamp":1673867211393,"user_tz":-60,"elapsed":410,"user":{"displayName":"딥러닝호형","userId":"11263585794403583722"}}},"source":["# https://pytorch.org/docs/stable/torchvision/transforms.html에서 다양한 전처리 방법들을 확인할 수 있다.\n","# tr.Compose 내에 원하는 전처리를 차례대로 넣어주면 된다.\n","\n","transf = tr.Compose([tr.Resize(16),tr.ToTensor()]) # 16x16으로 이미지 크기 변환 후 텐서 타입으로 변환한다.\n","\n","# Transforms on PIL Image\n","# Pad, Grayscale, RandomCrop, Normalize ..\n","# Transforms on torch.*Tensor - tensor image\n","# torchvision.transforms.ToPILImage(mode=None)...\n","# ... \n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"TKsBJMOLwlGA"},"source":["# https://pytorch.org/docs/stable/torchvision/datasets.html에서 다양한 이미지 데이터셋을 확인할 수 있다.\n","# torchvision.datasets에서 제공하는 CIFAR10 데이터를 불러온다.\n","# root에는 다운로드 받을 경로를 입력한다.\n","# train=Ture이면 학습 데이터를 불러오고 train=False이면 테스트 데이터를 불러온다.\n","# 미리 선언한 전처리를 사용하기 위해 transform=transf을 작성한다.\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_DgnpPXnwlGB"},"source":["# 일반적으로 데이터셋은 이미지와 라벨이 동시에 들어있는 튜플(tuple) 형태다. (이미지, 라벨)\n","# trainset[0]은 학습 데이터의 첫 번째 데이터로 이미지 한 장과 라벨 숫자 하나가 저장되어 있다.\n","# 즉, trainset[0][0]은 이미지이며 trainset[0][1]은 라벨이다.\n","\n","print(trainset[0][0].size()) \n","\n","# 현재 이미지 사이즈는 3x16x16이다. 여기서 3은 채널 수를 말하고 16x16은 이미지의 너비와 높이를 의미한다.\n","# 일반적인 컬러 사진은 RGB 이미지이기 때문에 채널이 3개 이고 (높이)x(너비)x(채널 수)로 크기가 표현된다.\n","# 하지만 파이토치에서는 이미지 한 장이 (채널 수)x(높이)x(너비)으로 표현되니 유의하도록 한다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B10b8fwDwlGC"},"source":["# DataLoader는 데이터를 미니 배치 형태로 만들어 준다.\n","# 따라서 배치 사이즈 및 셔플 여부 등을 선택할 수 있다.\n","trainloader = DataLoader(trainset, batch_size=50, shuffle=True)\n","testloader = DataLoader(testset, batch_size=50, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1c9NVqKwlGC"},"source":["len(trainloader)\n","# CIFAR10의 학습 이미지는 50,000장이고 배치 사이즈가 50장이므로 1,000은 배치의 개수가 된다.\n","# 즉 trainloader가 잘 만들어졌다는 것을 단편적으로 알 수 있다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7OvIBgfwlGD"},"source":["# iter, next를 이용해 일부 데이터를 확인할 수 있다.\n","dataiter = iter(trainloader)\n","images, labels = dataiter.next()\n","\n","print(images.size())\n","# 일반적으로 학습 데이터는 4차원 형태로 모델에서 사용된다.\n","# (배치 크기)x(채널 수)x(높이)x(너비)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4HNsa177wlGD"},"source":["## 3.2 같은 클래스 별로 폴더를 정리한 경우"]},{"cell_type":"code","metadata":{"id":"-zrB3gCBzvqb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673867236588,"user_tz":-60,"elapsed":21768,"user":{"displayName":"딥러닝호형","userId":"11263585794403583722"}},"outputId":"098c22ce-7a1d-44a0-fb01-3a7a3575c8ed"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"-1rMc-D-z4WD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673867237408,"user_tz":-60,"elapsed":828,"user":{"displayName":"딥러닝호형","userId":"11263585794403583722"}},"outputId":"9b3fca5b-b4c1-4918-a8fa-aea29d046211"},"source":["cd/content/gdrive/My Drive/deeplearningbro/pytorch"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/deeplearningbro/pytorch\n"]}]},{"cell_type":"code","metadata":{"id":"cabCxEb_wlGE","executionInfo":{"status":"ok","timestamp":1673867280509,"user_tz":-60,"elapsed":1127,"user":{"displayName":"딥러닝호형","userId":"11263585794403583722"}}},"source":["# 데이터가 같은 클래스 별로 미리 폴더를 정리 된 경우, ImageFolder의 1줄 선언으로 개인 데이터를 사용할 수 있다.\n","# 별도의 라벨링이 필요 없으며 폴더 별로 자동으로 라벨링을 한다.\n","# 예를 들어 class 폴더에 tiger, lion 폴더(./class/tiger와 ./class/lion)를 미리 만든다.\n","# 다음으로 ImageFolder에 상위 폴더 ./class를 입력하면 이미지와 라벨이 정리 되어 데이터를 불러온다.\n","\n","transf = tr.Compose([tr.Resize((128, 128)),tr.ToTensor()]) # 128x128 이미지 크기 변환 후 텐서로 만든다.\n","trainset = torchvision.datasets.ImageFolder(root='./class', transform=transf) # 커스텀 데이터 불러온다.\n","trainloader = DataLoader(trainset, batch_size=2, shuffle=False) # 데이터를 미니 배치 형태로 만들어 준다."],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LGoDEHxNnQQ2","executionInfo":{"status":"ok","timestamp":1673867445844,"user_tz":-60,"elapsed":1175,"user":{"displayName":"딥러닝호형","userId":"11263585794403583722"}},"outputId":"7f153f01-49c5-42b8-88fb-607c0287dca6"},"source":["dataiter = iter(trainloader)\n","images, labels = next(dataiter) #images, labels = dataiter.next()\n","\n","print(images.size(), labels)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 3, 128, 128]) tensor([0, 1])\n"]}]},{"cell_type":"markdown","metadata":{"id":"OEf1xivnwlGE"},"source":["## 3.3 정형화 되지 않은 커스텀 데이터 불러오기(3.2를 사용할 수 없는 경우)\n","\n","\n","1) 라벨 별로 아름답게 폴더 정리가 되어 있으면 매우 좋겠지만 그렇지 않은 경우가 매우 많다.\n","\n","2) 다른 작업들과 공유 된 데이터인 경우 폴더를 함부로 정리할 수 없다.\n","\n","3) 이미지 데이터라도 이미지가 아닌 텍스트, 리스트, 배열 등으로 저장 되어 있는 경우도 있다. \n","\n"]},{"cell_type":"code","metadata":{"id":"2_soZ7DBwlGE"},"source":["# 32x32 컬러 이미지와 라벨이 각각 100장이 있다고 가정하다.\n","\n","train_images = np.random.randint(256,size=(100,32,32,3)) # (이미지 수)x(높이)x(너비)x(채널 수)\n","train_labels = np.random.randint(2,size=(100,1)) # 라벨 수\n","\n","# 이미지 전처리 작업이 필요할 경우 openCV와 같은 라이브러리를 이용하여 이 곳에서 작업할 수도 있다.\n","# 필자는 이 단계에서 전처리하는 것을 선호한다. 그 이유는 torchvision.transforms 라이브러리 보다\n","# OpenCV, SciPy와 같은 라이브러리가 더 많은 전처리 기술을 제공하며 이미지를 미리 처리해 놓고 전처리 된 이미지를 살펴보면서 \n","# 작업하는 것을 좋아하기 때문이다. 따라서 사용 목적과 편의성에 맞게 본인이 전처리를 어디서 할 지 정하면 될 것이다.\n","\n","#......\n","#......\n","#......\n","#train_images, train_labels = preprocessing(train_images, train_labels)\n","#......\n","#......\n","#......\n","\n","print(train_images.shape, train_labels.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pt6PIROIwlGF"},"source":["\"\"\"\n","from torch.utils.data import Dataset\n","\n","class MyDataset(Dataset):\n","    \n","    def __init__(self):\n","    \n","    def __getitem__(self, index):\n","    \n","    def __len__(self):\n","\n","이 양식을 통으로 가지고 다니자!!\n","\"\"\"\n","\n","class TensorData(Dataset):\n","\n","    def __init__(self, x_data, y_data):\n","        self.x_data = torch.FloatTensor(x_data) # 이미지 데이터를 FloatTensor로 변형\n","        self.x_data = self.x_data.permute(0,3,1,2) # (이미지 수)x(높이)x(너비)x(채널 수) -> (배치 크기)x(채널 수)x(높이)x(너비)\n","        self.y_data = torch.LongTensor(y_data) # 라벨 데이터를 LongTensor로 변형\n","        self.len = self.y_data.shape[0] # 클래스 내의 들어 온 데이터 개수 \n","\n","    def __getitem__(self, index):\n","        return self.x_data[index], self.y_data[index] # 뽑아 낼 데이터를 적어준다.\n","\n","    def __len__(self):\n","        return self.len # 클래스 내의 들어 온 데이터 개수 \n","\n","# 파이토치에서는 (배치 크기)x(채널 수)x(너비)x(높이) 데이터가 사용 되므로 원래 데이터 (이미지 수)x(높이)x(너비)x(채널 수)를 변경해야만 한다. \n","# permute에서 0(이미지 수), 1(높이), 2(너비), 3(채널 수)을 0(이미지 수), 3(채널 수), 1(높이),2 (너비)로 바꿔주는 것이기 때문에\n","# .permute(0,3,1,2)을 사용하는 것이다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wc4NWa17wlGF"},"source":["train_data = TensorData(train_images,train_labels) # 텐서 데이터 불러오기 \n","train_loader = DataLoader(train_data, batch_size=10, shuffle=True) # 미니 배치 형태로 데이터 갖추기"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MtdblxUY1r5c"},"source":[],"execution_count":null,"outputs":[]}]}